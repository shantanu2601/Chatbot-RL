# Chatbot-RL

The repository contains the code for a Reinforcement Learning based chatbot implemented as part of Reinforcement Learning course project. In recent years, the use of chat technology, including dialogue systems and chatbots, has become increasingly prevalent in human-computer interaction. Chatbots are computer programs designed to simulate conversation with human users, often in natural language. They have been widely adopted in various industries, including customer service, healthcare, and education, as they offer a cost-effective and efficient way to provide personalized assistance and support.However, the current state-of-the-art neural models for dialogue generation tend to be shortsighted, as they predict utterances one at a time but ignore their influence on future predictions. This limitation can lead to incoherent or irrelevant responses that can frustrate users and decrease the effectiveness of chatbots in their respective applications.To address this issue, the proposed solution is to implement a deep reinforcement learning inspired chatbot that can model future reward while generating texts. By modeling future reward, the chatbot can consider the potential outcomes of its dialogue and generate responses that are more coherent and contextually appropriate.


We implement the paper [**"Deep Reinforcement Learning for Dialogue Generation"**](https://arxiv.org/pdf/1606.01541.pdf) by Li et. al. The results show that their approach outperforms existing state-of-the-art methods and represents a significant step forward in the field of dialogue generation. To contribute to this, we extend the work done by them by using global attention along with Bidirectional RNNs. The results show that we are able to generate better responses which are more semantically coherent and are not dull.
